{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "import shelve\n",
    "import time\n",
    "import re\n",
    "from collections import Counter\n",
    "import unicodedata\n",
    "from operator import itemgetter\n",
    "import webbrowser\n",
    "import os\n",
    "import random\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \n",
    "    def __init__(self, mode): \n",
    "        \n",
    "        # initializing knn K value from user\n",
    "        self.mode = mode\n",
    "        self.noOfClusters = 0\n",
    "        \n",
    "        if self.mode == 1:\n",
    "            try:\n",
    "                self.k_value = int(raw_input(\"Enter K value\"))\n",
    "                self.user_keywords = raw_input(\"Enter The search Keywords\\t\")\n",
    "            except:\n",
    "                print \"Oops! Looks like you entered the wrong value,\\nplease enter an integer value for k\"\n",
    "                self.__init__(mode)\n",
    "                \n",
    "            \n",
    "            \n",
    "        if self.mode == 2:\n",
    "            self.k_value = 15\n",
    "            try:\n",
    "                self.noOfClusters = int(raw_input(\"Enter no of clusters\\t\"))\n",
    "                self.user_keywords = raw_input(\"Enter The search Keywords\\t\")\n",
    "            except:\n",
    "                print \"Oops! Looks like you entered the wrong value,\\nplease enter an integer value for no of clusters\"\n",
    "                self.__init__(mode)\n",
    "                \n",
    "        \n",
    "        \n",
    "           \n",
    "    def showJobs(self):\n",
    "        agentInstance = Agent()\n",
    "        agentInstance.sensor(self.user_keywords, self.mode,self.k_value,self.noOfClusters)\n",
    "        jobLinks = agentInstance.actuator()\n",
    "        \n",
    "        if mode == 2:\n",
    "            jobLinks = self.kMeansClustering(jobLinks,self.noOfClusters)\n",
    "        \n",
    "            \n",
    "        htmlcontent = self.htmlmaker(mode,jobLinks)\n",
    "        htmlfile = open('CareerResults.html','w')\n",
    "        htmlfile.write(htmlcontent)\n",
    "        htmlfile.close()\n",
    "        webbrowser.open_new_tab('CareerResults.html')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Implementation of kMeansClustering \n",
    "    def kMeansClustering(self, jobLinks,k):\n",
    "        \n",
    "        # For selecting initial seed points from amongst the job links\n",
    "        \n",
    "        # selecting initial random seeds\n",
    "        \n",
    "        seedlist = []\n",
    "        for i in range(0,k):\n",
    "            seedlist.append(len(jobLinks)-(k*(i+1)))\n",
    "        \n",
    "        cluster_dict = {}\n",
    "        index_list = []\n",
    "        \n",
    "        \n",
    "        #jaccard distance\n",
    "        for index in seedlist:\n",
    "            seedkeys = jobLinks[index][1].keys()\n",
    "            cluster_dict[index] = {}\n",
    "            for i in range(0,len(jobLinks)):\n",
    "                matches = 0\n",
    "                if i == index or i in seedlist:\n",
    "                    continue\n",
    "                \n",
    "                currentkeys = jobLinks[i][1].keys() \n",
    "                allkeys = set(currentkeys).union(set(seedkeys))\n",
    "                \n",
    "                for key in currentkeys:\n",
    "                    if key in seedkeys:\n",
    "                        matches +=1\n",
    "                \n",
    "                jaccard_similarity = float(matches)/len(allkeys)\n",
    "                cluster_dict[index][i] = round(jaccard_similarity , 4)\n",
    "                \n",
    "                if i not in index_list:\n",
    "                    index_list.append(i)\n",
    "\n",
    "        # creating the initial clusters            \n",
    "        self.initialcluster = {}\n",
    "        for j in seedlist:\n",
    "            self.initialcluster[j]=[]\n",
    "            \n",
    "        for i in index_list:     \n",
    "            max_similarity = 0\n",
    "            for j in seedlist:\n",
    "                if cluster_dict[j][i] > max_similarity:\n",
    "                    max_similarity = cluster_dict[j][i]\n",
    "                    closest_centroid = j\n",
    "            \n",
    "            self.initialcluster[closest_centroid].append(i)\n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "        # recursive function for k-means algorithm\n",
    "        def itercluster(cluster):\n",
    "            \n",
    "            newseeds = []\n",
    "            index_list = []\n",
    "            \n",
    "            \n",
    "            # Finding the highest mode vectors in each cluster to make new centroids\n",
    "            for key,valuelist in cluster.items():\n",
    "                max_val = 0\n",
    "                for index in valuelist:\n",
    "                    currentvector = jobLinks[index][1]\n",
    "                    mode = max(currentvector.iteritems(), key=itemgetter(1))[1]\n",
    "                    if mode > max_val:\n",
    "                        max_val = mode\n",
    "                        newCentroid = index\n",
    "                newseeds.append(newCentroid)\n",
    "            \n",
    "\n",
    "            \n",
    "            #calculate jaccard similarity\n",
    "            jaccard_dict = {}\n",
    "            for index in newseeds:\n",
    "                newseedkeys = jobLinks[index][1].keys()\n",
    "                jaccard_dict[index] = {}\n",
    "                for i in range(0,len(jobLinks)):\n",
    "                    matches = 0\n",
    "                    if i == index or i in newseeds:\n",
    "                        continue\n",
    "                    currentkeys = jobLinks[i][1].keys() \n",
    "                    allkeys = set(currentkeys).union(set(newseedkeys))\n",
    "                \n",
    "                    for key in currentkeys:\n",
    "                        if key in newseedkeys:\n",
    "                            matches +=1\n",
    "                \n",
    "                    jaccard_similarity = float(matches)/len(allkeys)\n",
    "                    jaccard_dict[index][i] = round(jaccard_similarity , 4)\n",
    "\n",
    "\n",
    "                    if i not in index_list:\n",
    "                        index_list.append(i)\n",
    "                \n",
    "            # creating the new clusters            \n",
    "            self.newcluster = {}\n",
    "            for j in newseeds:\n",
    "                self.newcluster[j]=[]\n",
    "            \n",
    "            for i in index_list:     \n",
    "                max_similarity = 0\n",
    "                for j in newseeds:\n",
    "\n",
    "                    if jaccard_dict[j][i] > max_similarity:\n",
    "                        max_similarity = jaccard_dict[j][i]\n",
    "                        closest_centroid = j\n",
    "                        \n",
    "                self.newcluster[closest_centroid].append(i)\n",
    "            \n",
    "            self.curclusterarr = []\n",
    "            for key, value in self.newcluster.items():\n",
    "                list1 = value\n",
    "                list1.append(key)\n",
    "                self.curclusterarr.append(list1)\n",
    "                \n",
    "                \n",
    "            self.initclusterarr = []\n",
    "            for key, value in self.initialcluster.items():\n",
    "                list1 = value\n",
    "                list1.append(key)\n",
    "                self.initclusterarr.append(list1)\n",
    "            print self.curclusterarr\n",
    "            \n",
    "            #checking similarity of clusters and returning true for test value\n",
    "            if self.curclusterarr == self.initclusterarr:\n",
    "                return self.curclusterarr\n",
    "            else:\n",
    "                clusteringscore = 0\n",
    "                for i in range(0,k-1):\n",
    "                    similarity=difflib.SequenceMatcher(None,self.curclusterarr[i],self.initclusterarr[i])\n",
    "                    similarity = round(similarity.ratio(),6)\n",
    "                    if similarity >= 0.1:\n",
    "                        clusteringscore +=1\n",
    "                        \n",
    "                if clusteringscore >= 1:\n",
    "                    i=1\n",
    "                    for row in self.curclusterarr:\n",
    "                        print \"cluster \"+str(i)\n",
    "                        i+=1\n",
    "                        for element in row:\n",
    "                            print jobLinks[element][1]\n",
    "                    print \"\\n\\n\\nThank you.\"\n",
    "                    exit()\n",
    "                        \n",
    "                else: \n",
    "                    self.initialcluster = self.newcluster\n",
    "                    itercluster(self.initialcluster)\n",
    "                \n",
    "\n",
    "        itercluster(self.initialcluster)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #creates html markup for displaying result\n",
    "    def htmlmaker(self,mode,jobLinks): \n",
    "        tablerows = \"\"\n",
    "        \n",
    "        if self.mode == 1:\n",
    "            algo = \"KNN Algorithm with k - value as \"+str(self.k_value)\n",
    "            for row in jobLinks:\n",
    "                tablerows+='<tr><td><a href=\"https://'+ row[0]+'style=\"display:inline;text-overflow:ellipsis;\" \">'+row[0]+'</a><td></tr>'\n",
    "#         else:\n",
    "#             algo = \"KNN Algorithm and clustering algorithm with no. of clusters as\"+str(self.noOfClusters)\n",
    "#             for row in jobLinks:\n",
    "#                 print row\n",
    "                \n",
    "\n",
    "            contents = '''<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\"><html>\n",
    "            <head>\n",
    "              <meta content=\"text/html; charset=ISO-8859-1\" http-equiv=\"content-type\">\n",
    "              <script src=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js\"></script>\n",
    "              <link rel=\"stylesheet\" type=\"text/css\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css\">\n",
    "              <script src=\"https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js\"></script>\n",
    "              <title>Career Center</title>\n",
    "            </head>\n",
    "            <body>\n",
    "         <div class=\"container\">\n",
    "          <div class=\"jumbotron\">\n",
    "            <h1>Saketh's Career and Job Center Agent</h1>      \n",
    "            <p>\n",
    "            Following are the relusts for the search keywords : ''' + self.user_keywords+'''<br>\n",
    "            Using \n",
    "            '''+ algo +'''</p>\n",
    "      </div>\n",
    "    </div>\n",
    "     <table class=\"table table-hover\"><thead><tr><th>I have found the following job postings for you from www.acm.org, www.indeed.com, www.ieee.org\n",
    "            </th>\n",
    "          </tr>\n",
    "        </thead><tbody>\n",
    "        '''+tablerows+'''</tbody>\n",
    "      </table>\n",
    "    </div>\n",
    "    </body>\n",
    "    </html>'''\n",
    "            return contents\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "#    Recieves the keywords, mode, k_value and no of clusters from the environment and passes them to agent\n",
    "    def sensor(self, user_keywords, mode, k_value,nClusters):\n",
    "        self.user_keywords = user_keywords\n",
    "        self.mode = mode\n",
    "        self.k_value = k_value\n",
    "        self.nClusters = nClusters\n",
    "        self.agentFunction(self.user_keywords, self.mode,self.k_value,self.nClusters)\n",
    "\n",
    "    # Searches the lookup table and returns the k job links based on knn, which  I have optimized and designed\n",
    "    # while generating the lookuptable\n",
    "    def agentFunction(self, user_keywords, mode, k_value,nClusters):\n",
    "        jobLinks = []\n",
    "        self.lookuptable = lookUpTable(user_keywords)\n",
    "        self.jobLinks = self.lookuptable.controller()[:k_value]\n",
    "        \n",
    "        \n",
    "    # sends back the results\n",
    "    def actuator(self):\n",
    "        return self.jobLinks\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Stores a persistent lookup table using the shelve package which offers keys to \n",
    "# read, write and store data using key values in a file.\n",
    "class lookUpTable:\n",
    "    \n",
    "    def __init__(self, user_keywords):\n",
    "        \n",
    "        self.user_keywords = user_keywords.replace(\" \",\"+\").upper()\n",
    "        \n",
    "        # list of sites to scrape data from after\n",
    "        self.quote_pages = [\n",
    "                            \"http://jobs.ieee.org/jobs/results/keyword/\"+self.user_keywords, \n",
    "                            \"https://www.indeed.com/jobs?q=\"+self.user_keywords+\"&l=\", \n",
    "                            \"http://jobs.acm.org/jobs/results/keyword/\"+self.user_keywords+\"?radius=0\"\n",
    "                           ]\n",
    "        \n",
    "        self.special_chars = '[^a-zA-Z0-9]'\n",
    "        \n",
    "        \n",
    "        self.stop_words = ['a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are',\n",
    "      'aren\\'t', 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by',\n",
    "      'can\\'t', 'cannot', 'could', 'couldn\\'t', 'did', 'didn\\'t', 'do', 'does', 'doesn\\'t', 'doing', 'don\\'t', 'down',\n",
    "      'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn\\'t', 'has', 'hasn\\'t', 'have', 'haven\\'t',\n",
    "      'having', 'he', 'he\\'d', 'he\\'ll', 'he\\'s', 'her', 'here', 'here\\'s', 'hers', 'herself', 'him', 'himself',\n",
    "      'his', 'how', 'how\\'s', 'i', 'i\\'d', 'i\\'ll', 'i\\'m', 'i\\'ve', 'if', 'in', 'into', 'is', 'isn\\'t', 'it',\n",
    "      'it\\'s', 'its', 'itself', 'let\\'s', 'me', 'more', 'most', 'mustn\\'t', 'my', 'myself', 'no', 'nor', 'not', 'of',\n",
    "      'off', 'on', 'once', 'only', 'or', 'other', 'ought', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'same',\n",
    "      'shan\\'t', 'she', 'she\\'d', 'she\\'ll', 'she\\'s', 'should', 'shouldn\\'t', 'so', 'some', 'such', 'than', 'that',\n",
    "      'that\\'s', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'there\\'s', 'these', 'they',\n",
    "      'they\\'d', 'they\\'ll', 'they\\'re', 'they\\'ve', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up',\n",
    "      'very', 'was', 'wasn\\'t', 'we', 'we\\'d', 'we\\'ll', 'we\\'re', 'we\\'ve', 'were', 'weren\\'t', 'what', 'what\\'s',\n",
    "      'when', 'when\\'s', 'where', 'where\\'s', 'which', 'while', 'who', 'who\\'s', 'whom', 'why', 'why\\'s', 'with',\n",
    "      'won\\'t', 'would', 'wouldn\\'t', 'you', 'you\\'d', 'you\\'ll', 'you\\'re', 'you\\'ve', 'your', 'yours', 'yourself',\n",
    "      'yourselves'\n",
    "      ]\n",
    "        \n",
    "   \n",
    "    # Logic to check if the search words are there in the table already\n",
    "    # also checks to update the table ever 24 hours.\n",
    "    def controller(self):\n",
    "        # Open shelve file\n",
    "        self.lookup_shelf = shelve.open('careerlookup')\n",
    "        doc_obj = []\n",
    "        # if keywords already in shelve check for time difference\n",
    "        self.stop_words = [word.upper() for word in self.stop_words]\n",
    "        if self.user_keywords in self.lookup_shelf.keys():\n",
    "            old_time = self.lookup_shelf[self.user_keywords][1]\n",
    "            new_time = time.time()\n",
    "            \n",
    "            #if time difference greater than 24 hours scrap the web again\n",
    "            if new_time - old_time >  86400:\n",
    "                doc_obj = self.scrapper()\n",
    "            else:\n",
    "                # else return the object from the shelve\n",
    "                doc_obj = self.lookup_shelf[self.user_keywords][0]\n",
    "\n",
    "        else:\n",
    "            # scrap for search keywords \n",
    "            doc_obj = self.scrapper()\n",
    "\n",
    "        self.lookup_shelf.close()\n",
    "        return doc_obj\n",
    "            \n",
    "    \n",
    "    #todo retain special character if user keyword contains it.\n",
    "    def scrapper(self):\n",
    "        doc_obj = []\n",
    "        page = urllib2.urlopen(self.quote_pages[0])\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        table = soup.findAll('div',attrs={'class': 'aiResultsMainDiv'})\n",
    "        for div in table:\n",
    "            titlediv = div.find('div',attrs={'class':'aiResultTitle'})\n",
    "            link = 'jobs.ieee.org'+titlediv.find('a')['href'],\n",
    "            description = titlediv.find('a').contents[0]+\" \"+div.find('div',attrs={'class':'aiResultsDescriptionNoAdvert'}).get_text().strip()[:-19]\n",
    "            description = self.makeDocObject(description) \n",
    "            #  distance calculation\n",
    "            jaccardSimilarity = round(self.jaccard_similarity(self.user_keywords, description),4)\n",
    "            doc_obj.append([link[0], description, jaccardSimilarity]) \n",
    "   \n",
    "       \n",
    "        # scrapper for indeed.com\n",
    "        page = urllib2.urlopen(self.quote_pages[1])\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        table = soup.findAll('div',attrs={'class':'row result'})+soup.findAll('div',attrs={'class':' row result'})\n",
    "        #prepend https://www.indeed.com\n",
    "        for div in table:\n",
    "            link = 'www.indeed.com'+div.find('a')['href']\n",
    "            description =  div.find('a').get_text()+\" \"+div.find('div',attrs={'class':'paddedSummaryExperience'}).get_text().strip()+\" \"+ div.find('span',attrs={'class':'summary'}).get_text().strip()\n",
    "            description = self.makeDocObject(description) \n",
    "            #  distance calculation and storing \n",
    "            jaccardSimilarity = round(self.jaccard_similarity(self.user_keywords, description),4)\n",
    "            doc_obj.append([link, description, jaccardSimilarity]) \n",
    "\n",
    "\n",
    "        # scrapper for acm.org\n",
    "        page = urllib2.urlopen(self.quote_pages[2])\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        table = soup.findAll('div',attrs={'class': 'aiResultsMainDiv'})\n",
    "        for div in table:\n",
    "            titlediv = div.find('div',attrs={'class':'aiResultTitle'})\n",
    "            link = 'jobs.acm.org'+titlediv.find('a')['href'], \n",
    "            description = titlediv.find('a').contents[0]+\" \"+div.find('div',attrs={'class':'aiResultsDescriptionNoAdvert'}).get_text().strip()\n",
    "            description = self.makeDocObject(description) \n",
    "            #  distance calculation\n",
    "            jaccardSimilarity = round(self.jaccard_similarity(self.user_keywords, description),4)\n",
    "            doc_obj.append([link[0], description, jaccardSimilarity]) \n",
    "        \n",
    "        doc_obj = sorted(doc_obj, key=itemgetter(2), reverse= True)\n",
    "        self.lookup_shelf[self.user_keywords] = (doc_obj,time.time())\n",
    "        return doc_obj\n",
    "        \n",
    "    # preprocessing the text data, filtering data using stop words and removing special characters, converting to upper case and encoding the text\n",
    "    def makeDocObject(self, description):\n",
    "        description = unicodedata.normalize('NFKD', description).encode('ascii','ignore')\n",
    "        description = description.upper()\n",
    "        description = re.sub(self.special_chars,\" \", description)\n",
    "        description = description.split(\" \") \n",
    "        description = filter(None ,description)\n",
    "        description = set(description)-set(self.stop_words)\n",
    "        description = Counter(description)\n",
    "        return description\n",
    "    \n",
    "    #preprocessing the similarity metrics using jaccardian similarity\n",
    "    def jaccard_similarity(self, keywords, description):\n",
    "        matches = 0.0\n",
    "        for keyword in keywords.split('+'):\n",
    "            if keyword in description.keys():\n",
    "                matches = matches + 1\n",
    "        finalset = set(description.keys()).union(set(keywords.split(\"+\")))\n",
    "        return float(matches)/len(finalset)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-6-49ebf2ec9f99>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-49ebf2ec9f99>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    mode = int(raw_input(\"Enter 1 for KNN only mode or 2 for clustering mode and anything else to exit\\t\"))\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Exeuciton control for exiting the app\n",
    "    1 - only KNN algorithm mode\n",
    "    2 - Clustering mode clusters on 15 links returned by using KNN\n",
    "# Any arbitrary input is treated as exit\n",
    "\"\"\"\n",
    "\n",
    "mode = 1\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        mode = int(raw_input(\"Enter 1 for KNN only mode or 2 for clustering mode and anything else to exit\\t\"))\n",
    "        if mode == 1 or mode == 2:\n",
    "            CareerAgent = Environment(mode)\n",
    "            CareerAgent.showJobs()\n",
    "    except:\n",
    "        print \"Thank you for using Saketh's Career Agent, Good Bye!\"\n",
    "        break\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
